---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: '3'

env:
  TALOSCONFIG: '{{.TALOSCONFIG}}'

tasks:

  test:
    cmd: echo {{.TALOSCONFIG}}

  genconfig:
    desc: Generate the Talos configs [CLUSTER=main]
    cmd: talhelper -c {{.CLUSTER_DIR}}/bootstrap/talos/talconfig.yaml genconfig -s {{.CLUSTER_DIR}}/bootstrap/talos/talsecret.sops.yaml -o {{.CLUSTER_DIR}}/bootstrap/talos/clusterconfig
    requires:
      vars: [CLUSTER]
    preconditions:
      - test -f {{.CLUSTER_DIR}}/bootstrap/talos/talconfig.yaml
      - test -f {{.CLUSTER_DIR}}/bootstrap/talos/talsecret.sops.yaml

  apply-node:
    desc: Apply Talos config to a node [CLUSTER=main] [HOSTNAME=required]
    cmds:
      - task: down
      - talosctl apply-config --nodes {{.HOSTNAME}} --mode={{.MODE}} --file {{.CLUSTER_DIR}}/bootstrap/talos/clusterconfig/{{.CLUSTER}}-{{.HOSTNAME}}.yaml
      - talosctl --nodes {{.HOSTNAME}} health --wait-timeout=10m --server=false
      - task: up
    vars:
      MODE: '{{.MODE | default "auto"}}'
    requires:
      vars: [CLUSTER, HOSTNAME]
    preconditions:
      - talosctl --nodes {{.HOSTNAME}} get machineconfig
      - test -f {{.CLUSTER_DIR}}/bootstrap/talos/talconfig.yaml
      - test -f {{.CLUSTER_DIR}}/bootstrap/talos/clusterconfig/talosconfig

  upgrade-node:
    desc: Upgrade Talos on a single node [CLUSTER=main] [HOSTNAME=required]
    cmds:
      - task: down
      - talosctl --nodes {{.HOSTNAME}} upgrade --image="factory.talos.dev/installer{{if eq .TALOS_SECUREBOOT "false"}}-secureboot{{end}}/{{.TALOS_SCHEMATIC_ID}}:{{.TALOS_VERSION}}" --timeout=10m
      - talosctl --nodes {{.HOSTNAME}} health --wait-timeout=10m --server=false
      - task: up
    vars:
      TALOS_SCHEMATIC_ID:
        sh: yq '.nodes[] | select(.hostname == "{{.HOSTNAME}}") | .talosImageURL' {{.CLUSTER_DIR}}/bootstrap/talos/talconfig.yaml | awk -F/ '{print $NF}'
      TALOS_SECUREBOOT:
        sh: yq '.nodes[] | select(.hostname == "{{.HOSTNAME}}") | .machineSpec.secureboot' {{.CLUSTER_DIR}}/bootstrap/talos/talconfig.yaml
      TALOS_VERSION:
        sh: yq '.talosVersion' {{.CLUSTER_DIR}}/bootstrap/talos/talconfig.yaml
    requires:
      vars: [CLUSTER, HOSTNAME]
    preconditions:
      - curl -fsSL -o /dev/null --fail https://github.com/siderolabs/talos/releases/tag/{{.TALOS_VERSION}}
      - talosctl --nodes {{.HOSTNAME}} get machineconfig
      - talosctl config info
      - test -f {{.TALOSCONFIG}}
      - test -f {{.CLUSTER_DIR}}/bootstrap/talos/talconfig.yaml
      - which kubectl talosctl yq

  upgrade-cluster:
    desc: Upgrade Talos on the whole cluster [CLUSTER=main]
    cmds:
      - task: down
      - for: { var: HOSTNAMES }
        task: upgrade-node
        vars:
          HOSTNAME: '{{.ITEM}}'
          CLUSTER: '{{.CLUSTER}}'
          ROLLOUT: true
      - task: up
    vars:
      HOSTNAMES:
        sh: kubectl get nodes --output=jsonpath='{.items[*].metadata.name}'

  upgrade-k8s:
    desc: Upgrade Kubernetes across the whole cluster [CLUSTER=main]
    cmd: talosctl --nodes {{.KUBERNETES_CONTROLLER}} upgrade-k8s --to {{.KUBERNETES_VERSION}}
    vars:
      KUBERNETES_CONTROLLER:
        sh: talosctl config info --output json | jq --raw-output '.endpoints[]' | shuf -n 1
      KUBERNETES_VERSION:
        sh: yq '.kubernetesVersion' {{.TALHELPER_CONFIG_FILE}}
    preconditions:
      - msg: Missing talosconfig
        sh: test -f {{.TALOSCONFIG}}
      - msg: Unable to retrieve Talos config
        sh: talosctl config info &>/dev/null
      - msg: Node not found
        sh: talosctl --nodes {{.KUBERNETES_CONTROLLER}} get machineconfig &>/dev/null
      - msg: Upstream Kubernetes version not found
        sh: curl -fsSL -o /dev/null --fail https://github.com/siderolabs/kubelet/releases/tag/{{.KUBERNETES_VERSION}}

  soft-nuke:
    desc: Resets nodes back to maintenance mode [CLUSTER=main]
    prompt: This will destroy your cluster and reset the nodes back to maintenance mode... continue?
    cmd: talhelper gencommand reset --config-file {{.CLUSTER_DIR}}/bootstrap/talos/talconfig.yaml --out-dir {{.CLUSTER_DIR}}/bootstrap/talos/clusterconfig --extra-flags="--reboot {{- if eq .CLI_FORCE false }} --system-labels-to-wipe STATE --system-labels-to-wipe EPHEMERAL{{ end }} --graceful=false --wait=false" | bash
    preconditions:
      - { msg: "Argument (CLUSTER) is required", sh: "test -n {{.CLUSTER}}" }


  down:
    internal: true
    cmds: # add cmd for volsync suspend
      - until kubectl wait jobs --all --all-namespaces --for=condition=complete --timeout=5m &>/dev/null; do sleep 5; done
    preconditions:
      - which kubectl

  up:
    internal: true
    cmds: # add cmd for volsync resume
      - until kubectl wait jobs --all --all-namespaces --for=condition=complete --timeout=5m &>/dev/null; do sleep 5; done
    preconditions:
      - which kubectl

  kubeconfig:
    desc: Generate the kubeconfig for a Talos cluster [CLUSTER=main]
    cmd: talosctl kubeconfig --nodes {{.TALOS_CONTROLLER}} --force --force-context-name {{.CLUSTER}} {{.CLUSTER_DIR}}
    vars:
      TALOS_CONTROLLER:
        sh: talosctl config info --output json | jq --raw-output '.endpoints[]' | shuf -n 1
    requires:
      vars: [CLUSTER]
    preconditions:
      - talosctl config info
      - test -f {{.CLUSTER_DIR}}/bootstrap/talos/clusterconfig/talosconfig
      - which talosctl
